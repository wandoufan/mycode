# TextCNN


## 参考资料
> https://www.cnblogs.com/ModifyRong/p/11319301.html


## 基本概念
TextCNN使用卷积神经网络来处理文本分类问题，可以更好的捕捉局部相关性  


## 处理的文本数据
1. 文本和图片不一样，图片有长宽和深度(RGB)，对应到文本上，假设文本有m个词，每个词的向量维度为n  
则输入向量有m x n x 1个特征，其中深度可以看为1  
2. 需要注意：文本是一维数据, 虽然经过词向量生成了二维矩阵，但是对词向量做从左到右滑动来进行卷积没有意义  
例如，"今天" 对应的向量[0, 0, 0, 0, 1]，按窗口大小为1 x 2从左到右滑动得到[0,0], [0,0], [0,0], [0,1]  
这四个向量对应的都是"今天"这个词汇, 这种滑动没有帮助  
因此用来处理文本的卷积核的列数与词向量的维度要相同，卷积核只要从上到下滑动，不再需要从左到右滑动  


## 处理流程
1. 将文本通过词向量展开为二维矩阵作为最初的输入  
例如，输入文本有7个词组成，每个词向量的维度为5，可以看作是一个7 x 5个像素的图像或7 x 5的矩阵  
2. 在卷积层使用卷积核对输入矩阵从上到下逐行进行特征抽取  
例如，设置卷积核为3 x 5，即每次对3个词进行抽取，步长为1，即每次向下滑动1行  
通过卷积操作将7 x 5输入矩阵映射为5 x 1的输出矩阵(只有一列，其中每行的值为一次卷积的结果)  
3. 在池化层对输出矩阵进行特征选择  
例如，得到输出矩阵为[0, 1, 0, 2, 1]之后按照最大值池化可以得到[2]为池化层输出  
4. 在全连接层  
根据结果值计算文本属于某个类别的概率  


## TextCNN的优势
1. 网络结构简单，从而带来了参数数目少, 计算量少, 训练速度快等优势  