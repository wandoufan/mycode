# 长短期记忆人工神经网络(Long Short-Term Memory, LSTM)


## 参考资料
> https://blog.csdn.net/Jundesky/article/details/89365164


## 基本概念
LSTM也是一种循环神经网络，适合于处理和预测时间序列中间隔和延迟相对较长的重要事件，记忆时间更长  
LSTM是为了解决一般的RNN无法处理长距离的依赖的问题而专门设计出来的，可以避免常规RNN的梯度消失问题  


## 应用场景
1. 实体识别  


## LSTM克服梯度消失的原理
原始RNN的隐藏层只有一个输出值，即h，它对于短期的输入非常敏感  
LSTM再增加一个输出值，即c，让它来保存长期的状态，称为记忆细胞(cell state)  
记忆细胞就像一个传送带，可以把本次产生的信息传送给下一时刻，而具体传送什么信息是由三个门控制的  
1. 在 t 时刻，LSTM 的输入有三个：  
当前时刻网络的输入值 x_t、上一时刻 LSTM 的输出值 h_t-1、以及上一时刻的记忆细胞 c_t-1  
2. LSTM 的输出有两个：  
当前时刻 LSTM 输出值 h_t、和当前时刻的记忆细胞 c_t  
3. 细胞状态c_t由两部分相加组成：  
第一部分是上一时刻的记忆细胞 c_t-1 和遗忘门输出值 f_t(遗忘系数) 的乘积  
第二部分是当前时刻网络的输入值 x_t 和输入门输出值 a_t(输入系数) 的乘积  


## 输入门、遗忘门和输出门
LSTM中引入了输入门、遗忘门和输出门来作为记忆细胞的控制开关  
门的输出是值域为0到1之间的实数向量，用门的输出向量按元素乘以我们需要控制的那个向量  
当门输出为 0 时，任何向量与之相乘都会得到 0 向量，这就相当于什么都不能通过  
当门输出为 1 时，任何向量与之相乘都不会有任何改变，这就相当于什么都可以通过  
1. 输入门（input gate）  
输入门它决定了当前时刻网络的输入 x_t 有多少保存到细胞状态 c_t  
2. 遗忘门（forget gate）  
遗忘门是控制是否遗忘的，它决定了上一时刻的细胞状态 c_t-1 有多少保留到当前时刻 c_t  
3. 输出门（output gate）  
输出门控制记忆细胞 c_t 有多少输出到 LSTM 的当前输出值 h_t  


## LSTM模型的特点
1. 长短期记忆的隐藏层输出包括LSTM 输出值 h_t、和当前时刻的记忆细胞 c_t，只有h_t会传递到输出层  


## LSTM和GPU的比较