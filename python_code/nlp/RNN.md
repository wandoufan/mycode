# RNN(recurrent neural network)循环神经网络
RNN常用于处理前后数据有关联的序列化数据

## 参考资料：  
> https://www.cnblogs.com/buptzym/p/5437973.html

## 循环神经网络模型和传统神经网络模型的区别：  
* 它们都能处理一个一个的输入，传统神经网络模型中前后输入之间完全没有关系，但对于某些任务中前后输入的信息来自同一序列，即前后输入之间有关联，例如对一个句子中每个词进行词性标注时，每个词的前后位置词都会相互影响各自的词性。 
* 循环神经网络的隐藏层的输入值不仅包括本次的输入值，还包括上一次的隐藏层值，其中有权重矩阵来设置上一次隐藏层值作为本次输入的权重。
* 基础神经网络只能在输入层、隐藏层、输出层之间建立权重值连接，而RNN可以在隐藏层的每个神经元之间都建立权重值连接

## BPTT(back-propagation through time)算法
BPTT即随时间反向传播算法，是常用的训练RNN的方法，本质上还是BP算法，区别在于RNN处理的时间序列数据，所以要基于时间反向传播  
BPTT的中心思想和BP算法相同，沿着需要优化的参数的负梯度方向不断寻找更优的点直至收敛  


## SRNN(Sliced recurrent neural networks)切片循环神经网络
传统RNN的隐藏层中神经元的输入依赖于上一神经元的输出，即每一步计算都需要等待上一步计算完成，因此很难实现并行化处理  
SRNN是一种性能优化版的循环神经网络，在不改变循环单元的情况下，比RNN结构快135倍  
SRNN基于RNN结构进行改良，将输入序列切成等长的最小子序列，这样循环单元就可以在每一层的每一个子序列中同时运行  

## LSTM(Long Short-Term Memory)长短期记忆神经网络
LSTM是一种时间递归神经网络，适合于处理和预测时间序列中间隔和延迟相对较长的重要事件