
一般把学习模型在实际使用中遇到的数据称为测试数据；为了加以区分，模型评估
与选择中用于评估测试的数据集称为验证集


对机器学习模型进行性能度量中的相关概念：
1.在回归任务中：
最常用的性能度量是均方误差，即多次样本的结果和标准结果进行差值比对
差值越小代表越接近于标准结果
2.在分类任务中(包括二分类任务和多分类任务)：
错误率：分类错误的样本数占样本总数的比例
精度：分类正确的样本数占样本总数的比例
即错误率+精度=1
以判断是否是恶心肿瘤为例
查准率(precision):判断是恶性肿瘤数/(判断是恶性肿瘤数+判断是良性肿瘤数)
查全率(recall)：判断是恶性肿瘤数/样本中所有恶性肿瘤个数
查准率和查全率是一组矛盾的参数；想要增加准确率，就需要把最具把握的样本才判定
为恶性肿瘤；想要增加全面率，就需要把所有具有可能性的样本都判定为恶性肿瘤
F1参数用来平衡查准率和查全率，在不同的应用场景下来提供查准率或查全率
https://blog.csdn.net/ybdesire/article/details/53613628
https://blog.csdn.net/liweibin1994/article/details/76944056
https://www.cnblogs.com/zle1992/p/6689136.html



中文与英文的区别（为什么首先要做分词）：
对于我们每天打交道的中文来说，并没有类似英文空格的边界标志。
而理解句子所包含的词语，则是理解汉语语句的第一步。汉语自动分词的任务
，通俗地说，就是要由机器在文本中的词与词之间自动加上空格。

NLP的各个任务：

LTP：基础语言分析
例子：'他叫汤姆去拿外衣'
1.分词
2.词性标注
3.命名实体识别(一般是文本中的人名，地名等名词/片段)
输入分好的词的列表，输出识别出来的实体片段
4.句法依存分析
依存树，每个节点都是一个字词
5.语义角色标注
以'说'为例，A0'他'是施动者，A1'汤姆'是受动者，A2'去拿外衣'是具体动作
6.语义依存
依存图


NLP目前的主要困难:
1.数据稀疏性
中文的字词组合非常多
2.形式和语义之间的多对多关系：
歧义性：一个词有多个意思
长距离依赖：窗口位置很远的词都会影响当前词的意思
3.理解语言通常需要背景知识和推理能力


人工智能的相关概念：
机器学习
训练
预测


接下来NLP任务：

1.词级别任务：
中文分词
细粒度分词(多粒度分词)
新词发现(新词补充到词库)
词性标注
词表示(把词表示为向量)
近义词(输入一个词可以查询出近义词)
同义词(输入一个词可以查询出同义词)

2.中文分词




boson的key
i40gg8St.23519.bgKF4eMppJf1
Ai--RCey.23903.grgfARvZkxUJ
IXZThpiK.23905.gYrbW0nhfYdN
GZBZ2cPs.23906.Y9PNaLSiWu7x
0cGxaW_g.23908.6pC0CMGLWG_m
jV4QqS4M.23907.Vuel9a3kj5Xz
jEZvAklS.23354.lVAvotHNcQyR
RXYnypIB.23511.iJ4hKGOxz7bg