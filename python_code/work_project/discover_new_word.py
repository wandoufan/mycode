# 项目时间
# 2018.7-2018.8

# 项目背景
# 在中文的自然语言处理中，对文本处理的第一步是分词，分词的的重要基础就是词典。
# 现有的词典存在的一个重大缺陷就是词普遍老旧，未能及时收录新出现的词语，导致了对一些新词进行切分时效果不佳。
# 新词发现项目的目标就是从大规模语料中自动识别出合法词语，并经过词典过滤后获取词典中没有收录的新词。

# 工作内容
# 1.通过对语料中文本片段的词频、左右熵、聚合度等属性进行计算，并综合打分选取其中成词概率较高的文本片段。
# 2.通过调用分词系统接口对候选词进行过滤。
# 3.不断优化算法，修复Bug，并使用cython提高代码性能。

# 工作业绩
# 1.通过只计算出n元文本片段的左右熵来近似替代n元以上文本片段的左右熵，大大降低了程序计算量。
# 2.通过记录文本片段的位置信息来修正文本片段的左右熵，提高了程序结果的准确率。